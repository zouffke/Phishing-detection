{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**NOTE**\n",
    "We started building this document but then noticed that the HyperParameter tuning notebook already did what we needed to do for the model evaluation so we did not complete this notebook."
   ],
   "id": "50616c27f52e359c"
  },
  {
   "cell_type": "markdown",
   "id": "b75e4b7f",
   "metadata": {},
   "source": [
    "\n",
    "# Model Building and Evaluation\n",
    "\n",
    "In this notebook, we will be building and evaluating different machine learning models to classify URLs as either `phishing` or `legitimate`. \n",
    "\n",
    "## Steps:\n",
    "1. Load the preprocessed dataset\n",
    "2. Split the dataset into training and testing sets\n",
    "3. Train multiple machine learning models\n",
    "4. Evaluate the models using accuracy, precision, recall, and F1-score\n",
    "5. Perform cross-validation to validate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6c3ff57cc54ee17",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Load the preprocessed dataset (replace the path with your actual file path)\n",
    "data = pd.read_csv('../data/norm_data.csv')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.copy()\n",
    "y = X.pop('label')\n",
    "\n",
    "X.pop('url')\n",
    "\n",
    "# Convert the target labels to binary format\n",
    "y = y.map({'phishing': 1, 'legitimate': 0})\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n"
   ],
   "id": "06068aec"
  },
  {
   "cell_type": "markdown",
   "id": "bba60480",
   "metadata": {},
   "source": [
    "\n",
    "We begin by loading the preprocessed dataset and splitting it into training and testing sets.\n",
    "We use 80% of the data for training the models and reserve 20% for testing the models' performance.\n",
    "\n",
    "The target variable (`label`) is converted to a binary format where:\n",
    "- `1` represents `phishing`\n",
    "- `0` represents `legitimate`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "830f8650",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-06T20:45:09.231550300Z",
     "start_time": "2024-10-06T20:05:04.253385Z"
    }
   },
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the models\n",
    "log_reg = LogisticRegression()\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "# Train the models\n",
    "log_reg.fit(X_train, y_train)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "svm_clf.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\pythonenvironments\\data_exploration_modelling\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a7186c7",
   "metadata": {},
   "source": [
    "\n",
    "We are training four machine learning models:\n",
    "1. **Logistic Regression**: A simple linear model for classification.\n",
    "2. **Decision Tree**: A non-linear model that splits data based on feature values.\n",
    "3. **Random Forest**: An ensemble model that builds multiple decision trees and averages their predictions.\n",
    "4. **Support Vector Machine (SVM)**: A model that finds the hyperplane which best separates the classes.\n",
    "\n",
    "Each model is trained on the training set (`X_train`, `y_train`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b11d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "tree_clf_pred = tree_clf.predict(X_test)\n",
    "rf_clf_pred = rf_clf.predict(X_test)\n",
    "svm_clf_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Logistic Regression Accuracy: \", accuracy_score(y_test, log_reg_pred))\n",
    "print(\"Decision Tree Accuracy: \", accuracy_score(y_test, tree_clf_pred))\n",
    "print(\"Random Forest Accuracy: \", accuracy_score(y_test, rf_clf_pred))\n",
    "print(\"SVM Accuracy: \", accuracy_score(y_test, svm_clf_pred))\n",
    "\n",
    "# Classification report for more detailed evaluation\n",
    "print(\"Logistic Regression Report:\", classification_report(y_test, log_reg_pred))\n",
    "print(\"Decision Tree Report:\", classification_report(y_test, tree_clf_pred))\n",
    "print(\"Random Forest Report:\", classification_report(y_test, rf_clf_pred))\n",
    "print(\"SVM Report:\", classification_report(y_test, svm_clf_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aec28b",
   "metadata": {},
   "source": [
    "\n",
    "We evaluate the models using the following metrics:\n",
    "1. **Accuracy**: The percentage of correct predictions out of all predictions.\n",
    "2. **Precision**: The percentage of true positives out of all positive predictions.\n",
    "3. **Recall**: The percentage of true positives out of all actual positives.\n",
    "4. **F1-score**: The harmonic mean of precision and recall, providing a balance between the two.\n",
    "\n",
    "We generate detailed classification reports for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e54456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "log_reg_cv = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "tree_clf_cv = cross_val_score(tree_clf, X_train, y_train, cv=5)\n",
    "rf_clf_cv = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
    "svm_clf_cv = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"Logistic Regression Cross-Val Scores: \", log_reg_cv)\n",
    "print(\"Decision Tree Cross-Val Scores: \", tree_clf_cv)\n",
    "print(\"Random Forest Cross-Val Scores: \", rf_clf_cv)\n",
    "print(\"SVM Cross-Val Scores: \", svm_clf_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c0ef9",
   "metadata": {},
   "source": [
    "\n",
    "We also perform cross-validation with 5 folds to assess the stability and generalizability of the models.\n",
    "Cross-validation helps reduce overfitting by training the model on different subsets of the data and evaluating its performance on unseen data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
